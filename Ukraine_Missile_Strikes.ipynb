{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 7929493,
          "sourceType": "datasetVersion",
          "datasetId": 3173312
        }
      ],
      "dockerImageVersionId": 30673,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis of Russian Missile and Drone Attacks against Ukraine\n",
        "\n",
        "Can we identify potential targets of missile and drone strikes before they land?\n",
        "\n",
        "This dataset contains available information about launched and shot down missiles and drones during Russian large-scale missile and drone (UAV) strikes on infrastructure (since October 2022) as part of its invasion of Ukraine. The dataset also contains information about some single shot-down UAVs.\n",
        "\n",
        "The dataset was created manually based on the official reports of Air Force Command of UA Armed Forces and General Staff of the Armed Forces of Ukraine published on social media such as Facebook and Twitter.\n",
        "You can find a short description of each data feature below:\n",
        "\n",
        "    time_start - start attack time,\n",
        "    time_end - end attack time,\n",
        "    model - missile or UAV type,\n",
        "    launch_place - city or region from missiles were launched,\n",
        "    target - could be a city in Ukraine, or region of Ukraine or direction, or full Ukraine,\n",
        "    carrier - missile launch platform,\n",
        "    launched - number of launched missiles or UAVs,\n",
        "    destroyed - number of destroyed missiles or UAVs,\n",
        "    source - information source (mainly facebook posts)\n",
        "\n",
        "\n",
        "\n",
        "We will attempt to probabilistically model this dataset using a Naive Bayes classifier from scratch, not using any premade implementations.\n",
        "\n",
        "If we are able to predict strike locations, then Ukraine could devise an early warning system that would save civilian lives and protect critical infrastructure.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-03-24T18:01:55.167809Z",
          "iopub.execute_input": "2024-03-24T18:01:55.169165Z",
          "iopub.status.idle": "2024-03-24T18:01:55.180514Z",
          "shell.execute_reply.started": "2024-03-24T18:01:55.169122Z",
          "shell.execute_reply": "2024-03-24T18:01:55.179176Z"
        },
        "id": "YchY9Vz_UVKq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bayesian Classification\n",
        "\n",
        "Naive Bayes classifiers are built on Bayesian classification methods.\n",
        "These rely on Bayes's theorem, which is an equation describing the relationship of conditional probabilities of statistical quantities.\n",
        "In Bayesian classification, we're interested in finding the probability of a label $L$ given some observed features, which we can write as $P(L~|~{\\rm features})$.\n",
        "Bayes's theorem tells us how to express this in terms of quantities we can compute more directly:\n",
        "\n",
        "$$\n",
        "P(L~|~{\\rm features}) = \\frac{P({\\rm features}~|~L)P(L)}{P({\\rm features})}\n",
        "$$\n",
        "\n",
        "If we are trying to decide between two labels—let's call them $L_1$ and $L_2$—then one way to make this decision is to compute the ratio of the posterior probabilities for each label:\n",
        "\n",
        "$$\n",
        "\\frac{P(L_1~|~{\\rm features})}{P(L_2~|~{\\rm features})} = \\frac{P({\\rm features}~|~L_1)}{P({\\rm features}~|~L_2)}\\frac{P(L_1)}{P(L_2)}\n",
        "$$\n",
        "Thus removing the need to compute $P(features)$.\n",
        "\n",
        "\n",
        "All we need now is some model by which we can compute $P({\\rm features}~|~L_i)$ for each label.\n",
        "Such a model is called a *generative model* because it specifies the hypothetical random process that generates the data.\n",
        "Specifying this generative model for each label is the main piece of the training of such a Bayesian classifier.\n",
        "The general version of such a training step is a very difficult task, but we can make it simpler through the use of some simplifying assumptions about the form of this model.\n",
        "\n",
        "This is where the \"naive\" in \"naive Bayes\" comes in: if we make very naive assumptions about the generative model for each label, we can find a rough approximation of the generative model for each class, and then proceed with the Bayesian classification."
      ],
      "metadata": {
        "id": "jcpyce-7z9wI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Dataset"
      ],
      "metadata": {
        "id": "EQec9Am5lvk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/SOCOM-Ignite/ML_AI_Kickoff/releases/download/v1.0.0/UkraineMissileAttacks.zip\n",
        "!unzip -o UkraineMissileAttacks.zip -d data/"
      ],
      "metadata": {
        "id": "emERC_SWZRg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries"
      ],
      "metadata": {
        "id": "4StkAEM2UVKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime, timedelta\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T18:11:44.059742Z",
          "iopub.execute_input": "2024-03-24T18:11:44.060298Z",
          "iopub.status.idle": "2024-03-24T18:11:44.079128Z",
          "shell.execute_reply.started": "2024-03-24T18:11:44.060258Z",
          "shell.execute_reply": "2024-03-24T18:11:44.077744Z"
        },
        "trusted": true,
        "id": "64b34xKjUVKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing Data"
      ],
      "metadata": {
        "id": "Oq27MzKeUVKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Data Import and Join ###\n",
        "df1 = pd.read_csv(\"data/missile_attacks_daily.csv\")\n",
        "df2 = pd.read_csv(\"data/missiles_and_uav.csv\")\n",
        "df = pd.merge(df1, df2, on='model', how='left')\n",
        "\n",
        "### Converting time_start and time_end to datetime objects ###\n",
        "df['date_start'] = pd.to_datetime(df['time_start'], errors='coerce')\n",
        "default_date = pd.to_datetime('2024-03-24')\n",
        "df['date_start'].fillna(default_date, inplace=True)\n",
        "df['date_start'] = df['date_start'].astype(str)\n",
        "\n",
        "### Data Cleanup ###\n",
        "def normalize_strings(sample):\n",
        "    sample = str(sample).replace('and', ',')\n",
        "    sample = [location.lstrip().rstrip() for location in sample.split(',')]\n",
        "    sample = ','.join(sample)\n",
        "    return sample\n",
        "\n",
        "df['target'] = df['target'].map(normalize_strings)\n",
        "df['model'] = df['model'].map(normalize_strings)\n",
        "df['launch_place'] = df['launch_place'].map(normalize_strings)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-03-24T18:11:44.081972Z",
          "iopub.execute_input": "2024-03-24T18:11:44.08249Z",
          "iopub.status.idle": "2024-03-24T18:11:44.113827Z",
          "shell.execute_reply.started": "2024-03-24T18:11:44.082442Z",
          "shell.execute_reply": "2024-03-24T18:11:44.112141Z"
        },
        "trusted": true,
        "id": "beA5jxn5UVKv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "ORU8XHJWtXUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Encode features as binary vectors ###\n",
        "def binarize_column(df, column_name):\n",
        "    unique_values = df[column_name].unique()\n",
        "    new_columns = []\n",
        "    for value in unique_values:\n",
        "        new_columns.extend(value.split(','))\n",
        "\n",
        "    new_columns = set(f\"{column_name}_{value}\" for value in new_columns if value not in ('', 'nan'))\n",
        "\n",
        "    new_columns = pd.DataFrame(0, columns=list(new_columns), index=df.index)\n",
        "\n",
        "    for i, element in enumerate(df[column_name]):\n",
        "        for x in element.split(','):\n",
        "            if x not in ('', 'nan'):\n",
        "                new_columns.at[i, f\"{column_name}_{x}\"] = 1\n",
        "\n",
        "\n",
        "\n",
        "    return new_columns"
      ],
      "metadata": {
        "id": "rjbucBYO6I9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will attempt to predict the target location of strikes given launch location, types of drones/missiles involved, and number launched.\n",
        "$$\n",
        "P(\\text{target location}~|~{\\rm \\text{launch location, drone/missile model, number launched}})$$"
      ],
      "metadata": {
        "id": "_C_IuAHttjSG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.concat([binarize_column(df, 'target'), binarize_column(df, 'model'), binarize_column(df, 'launch_place'), df['launched']], axis=1)\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "aTTW3YfdfouX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "5hd9wtEgxboT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_labels(dataset, column_selector):\n",
        "    return dataset[[col for col in dataset.columns if column_selector(col)]]"
      ],
      "metadata": {
        "id": "yC_xOVtCGh2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = get_labels(train_dataset, lambda col: col.startswith('target_'))"
      ],
      "metadata": {
        "id": "BiF1rKFBD_oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating the prior\n",
        "To implement Naive Bayes, we need to compute the apriori class probabilities, $P(\\text{target location})$. While we could make the prior a uniform distribution, that would be uninformative. Here, we can compute a prior given our training labels.\n",
        "\n",
        "$$\\text{prior for a given class} = \\frac{\\text{no. of samples in that class}}{\\text{total no. of samples}}$$\n",
        "\n",
        "Using **y_train**, compute the prior."
      ],
      "metadata": {
        "id": "sJs2_X9of0zj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prior = # TODO: Implement the calculation for the prior"
      ],
      "metadata": {
        "id": "w9aeNNZQf0EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Make sure this cell passes before moving on!\n",
        "assert (prior.index == y_train.columns).all()\n",
        "assert prior.sum() == 1"
      ],
      "metadata": {
        "id": "NygTfvBmh08W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For computing the likelihood $P(\\text{launched}~|~\\text{target location})$, we will assume the feature is a Gaussian distribution. The calculation for the Gaussian likelihood is:\n",
        "$$P(x_i~|~y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}}\\exp \\Bigg( -\\frac{(x_i-\\mu_y)^2}{2\\sigma^2_y} \\Bigg) $$"
      ],
      "metadata": {
        "id": "_lilm4Ayiadl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_gaussian_likelihood_params(dataset, column):\n",
        "    likelihood_params = pd.DataFrame(columns=y_train.columns, index=['mean', 'std'], dtype=float)\n",
        "    for col in y_train.columns:\n",
        "        likelihood_params.loc['mean', col] = dataset.loc[dataset[col] == 1, column].mean()\n",
        "        likelihood_params.loc['std', col] = dataset.loc[dataset[col] == 1, column].std()\n",
        "\n",
        "    stds = likelihood_params.loc['std']\n",
        "    std_min = likelihood_params.loc['std', stds > 0].min()\n",
        "    likelihood_params.loc['std'] = likelihood_params.loc['std'].fillna(std_min)\n",
        "    likelihood_params.loc['std', stds < std_min] = std_min\n",
        "    return likelihood_params"
      ],
      "metadata": {
        "id": "dEcBZbHMFKpt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_gaussian_likelihood(likelihood_params, x):\n",
        "    # expects x to have shape [1, c]\n",
        "    x = x.transpose()\n",
        "    mu = likelihood_params.loc[['mean']].to_numpy()\n",
        "    sigma = likelihood_params.loc[['std']].to_numpy()\n",
        "    likelihood = 1 / np.sqrt(2 * np.pi * (sigma**2)) * np.exp(-1 * (x - mu)**2 / (2 * (sigma**2)))\n",
        "    return pd.DataFrame(data=likelihood, columns=likelihood_params.columns)"
      ],
      "metadata": {
        "id": "XS_gTi9hZz8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "likelihood_params_launched = calc_gaussian_likelihood_params(train_dataset, 'launched')"
      ],
      "metadata": {
        "id": "ByBA1o5uO4xP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "calc_gaussian_likelihood(likelihood_params_launched, np.array([[1,2,3]]))"
      ],
      "metadata": {
        "id": "BQUtPeMs-A_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the model type $P(\\text{model}~|~\\text{target})$ and launch location$P(\\text{launch_location}~|~\\text{target})$, we will use the Bernoulli Naive Bayes likelihood. The equation is\n",
        "$$P(x_i~|~y) = P(x_i=1|y)x_i + (1-P(x_i=1|y))(1-x_i)$$"
      ],
      "metadata": {
        "id": "MrAoZkDGkQkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_bernoulli_likelihood_params(dataset, column_selector):\n",
        "\n",
        "    likelihood_params = pd.DataFrame(\n",
        "        index=[col for col in dataset.columns if column_selector(col)],\n",
        "        columns=y_train.columns,\n",
        "        dtype=float\n",
        "    )\n",
        "\n",
        "    for col in likelihood_params.columns:\n",
        "        likelihood_params.loc[:, col] = dataset.loc[dataset[col] == 1, likelihood_params.index].mean(axis=0)\n",
        "\n",
        "    likelihood_params = likelihood_params.fillna(0)\n",
        "    return likelihood_params"
      ],
      "metadata": {
        "id": "npPoie-SBY7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_bernoulli_likelihood(likelihood_params, x):\n",
        "    x_ = x.to_numpy().transpose()\n",
        "    likelihood_params_ = likelihood_params.to_numpy() # cxt\n",
        "    bernoulli_likelihood = np.multiply(x_, likelihood_params_) + np.multiply(1 - x_, 1 - likelihood_params_)\n",
        "    return pd.DataFrame(data=bernoulli_likelihood,\n",
        "                        columns=likelihood_params.columns,\n",
        "                        index=likelihood_params.index)"
      ],
      "metadata": {
        "id": "5fvW2oXnHyw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "likelihood_params_model = calc_bernoulli_likelihood_params(train_dataset, lambda col: col.startswith('model_'))\n",
        "likelihood_params_launch_place = calc_bernoulli_likelihood_params(train_dataset, lambda col: col.startswith('launch_place_'))"
      ],
      "metadata": {
        "id": "qtxOfNZrQDh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing\n",
        "calc_bernoulli_likelihood(likelihood_params_model, train_dataset.loc[[0], likelihood_params_model.index])"
      ],
      "metadata": {
        "id": "kDIPDibFIcsr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = get_labels(train_dataset, lambda col: not col.startswith('target_'))\n",
        "y_test = get_labels(test_dataset, lambda col: col.startswith('target_'))\n",
        "X_test = get_labels(test_dataset, lambda col: not col.startswith('target_'))"
      ],
      "metadata": {
        "id": "1B4iFjl7a1wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, we have constructed a Bayes probability model. To turn this model into a classifier, we pair it with a decision rule. One common rule is to pick the hypothesis that is most probable so as to minimize the probability of misclassification; this is known as the *maximum a posteriori* or MAP decision rule. The corresponding classifier, a Bayes classifier, is the function that assigns a class label\n",
        "$\\hat{y} = C_k$ for some $k$:\n",
        "$$\n",
        "\\hat{y} = \\text{argmax}_{k\\in\\{1,\\ldots,K\\}}P(C_k)∏^n_{i=1}P(x_i~|~C_k)\n",
        "$$\n",
        "\n",
        "Since the target location is multilabel (the strike can hit multiple locations), we will return the top-k hypotheses from our classifier."
      ],
      "metadata": {
        "id": "w5DIrP-FmwaT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try playing around with the topk parameter!\n",
        "def make_prediction(sample, topk=3):\n",
        "    launch_place = sample.loc[[col for col in sample.index if col.startswith('launch_place_')]]\n",
        "    model = sample.loc[[col for col in sample.index if col.startswith('model_')]]\n",
        "    launched = sample['launched']\n",
        "\n",
        "    likelihood_launch_place = calc_bernoulli_likelihood(likelihood_params_launch_place, launch_place.to_frame().transpose())\n",
        "    likelihood_model = calc_bernoulli_likelihood(likelihood_params_model, model.to_frame().transpose())\n",
        "    likelihood_launched = calc_gaussian_likelihood(likelihood_params_launched, np.array([launched]))\n",
        "\n",
        "    likelihood = likelihood_launch_place.prod() * likelihood_model.prod() * likelihood_launched\n",
        "    # not actually the posterior probability, proportional to it\n",
        "    posterior = likelihood * prior\n",
        "    posterior = posterior.to_numpy().squeeze()\n",
        "    ind = np.argpartition(posterior, -topk)[-topk:]\n",
        "\n",
        "    prediction = np.zeros_like(posterior)\n",
        "    prediction[ind] = 1\n",
        "    return prediction\n"
      ],
      "metadata": {
        "id": "G5N9FJ7MTqXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will use recall as our metric of choice. In the context of defending against missile strikes, recall gives us the number of strike locations we predicted correctly divided by the total number of strike locations.\n",
        "\n",
        "Logically, false negatives in this context are far more concerning and deadly than false positives."
      ],
      "metadata": {
        "id": "G_quPwPSqKw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = []\n",
        "for (_, x), (_, y) in zip(X_test.iterrows(), y_test.iterrows()):\n",
        "    y_pred = make_prediction(x)\n",
        "    metrics.append(recall_score(y.to_numpy(), y_pred, average='binary', zero_division=1))\n",
        "\n",
        "print(\"Test set recall:\", np.mean(metrics))"
      ],
      "metadata": {
        "id": "UN9kK8rCU4Q0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenge 1\n",
        "Please also compute the precision score for our classifier.\n",
        "# Challenge 2\n",
        "Compute the baseline recall and precision if we were to simply use only the prior.\n",
        "# Challenge 3\n",
        "Another model that could be useful to Ukrainian operators would be if we could predict the type(s) of drones and missiles sent in an attack.\n",
        "Modify the notebook to compute $P(\\text{model}~|~\\text{target location, launch location, number of launches})$."
      ],
      "metadata": {
        "id": "RN6l-BS-ryBq"
      }
    }
  ]
}